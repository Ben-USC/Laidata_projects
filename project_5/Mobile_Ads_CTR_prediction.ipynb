{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Click-Through Rate Prediction\n",
    "### We use data of mobile ads to predict click-through rate\n",
    "### data source: https://www.kaggle.com/c/avazu-ctr-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a pip package in the current Jupyter kernel example:\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import random\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## orig_train_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\",\"true\").csv(\"./data/CTR_train.gz\")\n",
    "## orig_train_df.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## orig_train_df.filter(orig_train_df.click == 1).count()\n",
    "## result: 6865066"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## orig_train_df.filter(orig_train_df.click == 0).count()\n",
    "## result: 33563901"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###df.agg(countDistinct(\"some_column\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from pyspark.sql.functions import udf\n",
    "import pyspark.sql.types as SparkType\n",
    "\n",
    "#parse_date = lambda val : pd.datetime.strptime(val, '%y%m%d%H')\n",
    "\n",
    "get_hour = udf(lambda s: int(str(s)[-2]+str(s)[-1]), SparkType.IntegerType())\n",
    "get_id = udf(lambda s: int(s), SparkType.IntegerType())\n",
    "\n",
    "## extract hour info:\n",
    "train_df = orig_train_df.withColumn('int_hour', get_hour('hour')).drop('hour')\n",
    "## convert id to integer:\n",
    "train_df = train_df.withColumn(\"int_id\", train_df[\"id\"].cast(SparkType.IntegerType())).drop('id')\n",
    "\n",
    "\n",
    "## a list of column names\n",
    "ordered_columns = ['int_id', 'int_hour', 'C1', 'banner_pos', 'site_id', 'site_domain', 'site_category',\n",
    "                   'app_id', 'app_domain', 'app_category',\n",
    "                   'device_id', 'device_ip', 'device_model', 'device_type', 'device_conn_type',\n",
    "                   'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21', 'click']\n",
    "train_df = train_df.select(*ordered_columns)\n",
    "\n",
    "train_df.head(1)\n",
    "\n",
    "## result:\n",
    "# [Row(int_id=2096162817, int_hour=0, C1=1005, banner_pos=0, site_id='1fbe01fe', site_domain='f3845767',\n",
    "# site_category='28905ebd', app_id='ecad2386', app_domain='7801e8d9', app_category='07d7df22',\n",
    "# device_id='a99f214a', device_ip='ddd2926e', device_model='44956a24', device_type=1, device_conn_type=2,\n",
    "# C14=15706, C15=320, C16=50, C17=1722, C18=0, C19=35, C20=-1, C21=79, click=0)]\n",
    "'''\n",
    "\n",
    "### test.rdd.flatMap(lambda x: x).histogram(20)\n",
    "\n",
    "### df.columns\n",
    "### result_pdf = df.select(\"*\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#click_data = train_df.select(\"click\").toPandas()\n",
    "#click_data.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample 2 million data points from the original ~6G dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_train = 40428967  # total number of records in the training set\n",
    "n_sample = 2000000\n",
    "skipped_rows = sorted(random.sample(range(1, n_train), n_train - n_sample))\n",
    "\n",
    "## define data type for training and test sets:\n",
    "types_train = {\n",
    "    'id': np.dtype(int), 'click': np.dtype(int), 'hour': np.dtype(int), 'C1': np.dtype(int),\n",
    "    'banner_pos': np.dtype(int),'site_id': np.dtype(str), 'site_domain': np.dtype(str),\n",
    "    'site_category': np.dtype(str), 'app_id': np.dtype(str), 'app_domain': np.dtype(str),\n",
    "    'app_category': np.dtype(str), 'device_id': np.dtype(str), 'device_ip': np.dtype(str),\n",
    "    'device_model': np.dtype(str), 'device_type': np.dtype(int), 'device_conn_type': np.dtype(int),\n",
    "    'C14': np.dtype(int), 'C15': np.dtype(int), 'C16': np.dtype(int), 'C17': np.dtype(int), \n",
    "    'C18': np.dtype(int), 'C19': np.dtype(int), 'C20': np.dtype(int), 'C21':np.dtype(int)\n",
    "}\n",
    "\n",
    "types_test = { key:val for (key,val) in types_train.items() if key!= 'click'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "get_date = lambda s : pd.datetime.strptime(s, '%y%m%d%H')\n",
    "\n",
    "with gzip.open('./data/CTR_train.gz') as f:\n",
    "    train_df = pd.read_csv(f, parse_dates = ['hour'], date_parser = get_date,\n",
    "                         dtype = types_train, skiprows = skipped_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.countplot(x='click',data=train_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df['click'].value_counts())\n",
    "print(train_df['click'].value_counts()/len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.countplot(x='int_hour',data=train_df)\n",
    "train_df.groupby('hour').agg({'click':'sum'}).plot(figsize=(12,6))\n",
    "plt.ylabel('Number of clicks')\n",
    "plt.title('Number of clicks by hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add features: 'hour_of_day' and 'day_of_week'\n",
    "train_df['hour_of_day'] = train_df['hour'].apply(lambda t: t.hour)\n",
    "train_df['day_of_week'] = train_df['hour'].apply(lambda t: t.weekday_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.countplot(x='hour_of_day',data=train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.groupby(['hour_of_day', 'click']).size().unstack().plot(kind='bar',stacked=True, title=\"Hour of the Day\", figsize=(12,6))\n",
    "\n",
    "#train_df.groupby(['hour_of_day', 'click']).size().unstack().plot(kind='bar',stacked=True, title=\"Hour of the Day\", figsize=(12,6))\n",
    "\n",
    "plt.ylabel('count')\n",
    "plt.title('Clicks on hourly impressions vs. clicks');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.groupby(['day_of_week', 'click']).size().unstack().plot(kind='bar',stacked=True, title=\"Day of the week\", figsize=(12,6))\n",
    "\n",
    "#train_df.groupby(['hour_of_day', 'click']).size().unstack().plot(kind='bar',stacked=True, title=\"Hour of the Day\", figsize=(12,6))\n",
    "\n",
    "plt.ylabel('count')\n",
    "plt.title('day of week impressions vs. clicks');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.groupby(['C1', 'click']).size().unstack().plot(kind='bar', title=\"Value counts for C1\", figsize=(12,6))\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('C1 domain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.groupby(['banner_pos', 'click']).size().unstack().plot(kind='bar', title=\"Value counts for banner_pos\", figsize=(12,6))\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('banner_pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.groupby(['site_category', 'click']).size().unstack().plot(kind='bar', title=\"Value counts for site_category\", figsize=(12,6))\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('site_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.groupby(['app_category', 'click']).size().unstack().plot(kind='bar', title=\"Value counts for app_category\", figsize=(12,6))\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('app_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.groupby(['device_type', 'click']).size().unstack().plot(kind='bar', title=\"Value counts for device_type\", figsize=(12,6))\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('device_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df.groupby(['device_id', 'click']).size().unstack().plot(kind='bar', stacked=True, title=\"Value counts for device_id\", figsize=(12,6))\n",
    "#plt.ylabel('count')\n",
    "#plt.xlabel('device_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df.groupby(['device_ip', 'click']).size().unstack().plot(kind='bar', stacked=True, title=\"Value counts for device_ip\", figsize=(12,6))\n",
    "#plt.ylabel('count')\n",
    "#plt.xlabel('device_ip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.groupby(['device_conn_type', 'click']).size().unstack().plot(kind='bar', title=\"Value counts for device_conn_type\", figsize=(12,6))\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('device_conn_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['C15', 'C16', 'C18', 'C19', 'C21']\n",
    "for feature in features:\n",
    "    print(feature)\n",
    "    train_df.groupby([feature, 'click']).size().unstack().plot(kind='bar', title='Value counts for '+feature, figsize=(12,6))\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.xlabel(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop('id', axis=1, inplace=True)\n",
    "train_df.drop('hour', axis=1, inplace=True)\n",
    "#train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(train_df.columns)\n",
    "\n",
    "for c in columns:\n",
    "    #print(\"For column \" + c + \", number of unique value: \", train_df[c].value_counts())\n",
    "    print(\"For column \" + c + \", number of unique value: \", train_df[c].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_droped = {'click', 'device_id', 'device_ip'}\n",
    "\n",
    "tolerated_cols = {'hour_of_day','day_of_week', 'C1', 'banner_pos', \n",
    "             'site_category', 'app_category', 'device_type', 'device_conn_type', 'C15', 'C16', 'C18' }\n",
    "\n",
    "target_cols = [ c for c in list(train_df.columns) if c not in tolerated_cols and c not in to_be_droped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "## use OrderedDict to store unique value and 0, 1 counts for each column\n",
    "## then pickup the unique value that has more than certain number of samples\n",
    "\n",
    "def choose_domain_by_col(df, tolerated_cols, target_cols, thresh0, thresh1):\n",
    "    \n",
    "    col_domain = {}\n",
    "    \n",
    "    print(\"########## For tolerated columns: ##########\")\n",
    "    for c in tolerated_cols:\n",
    "        \n",
    "        tmp = []\n",
    "        val_count = OrderedDict(df[c].value_counts())\n",
    "        for key, count in val_count.items(): tmp.append(key)\n",
    "        col_domain[c] = list(set(tmp))\n",
    "        \n",
    "        print(f\"'{c}' domain size {len(col_domain[c])}\")  \n",
    "\n",
    "    print(\"########## For target columns: ##########\")\n",
    "    for c in target_cols:\n",
    "        tmp = []\n",
    "        tmp0 = OrderedDict(df.query(\"click == 0\")[c].value_counts())\n",
    "        tmp1 = OrderedDict(df.query(\"click == 1\")[c].value_counts())\n",
    "\n",
    "        for key, count in tmp0.items():\n",
    "            if count >= thresh0:\n",
    "                tmp.append(key)\n",
    "            else:\n",
    "                break\n",
    "        for key, count in tmp1.items():\n",
    "            if count >= thresh1:\n",
    "                tmp.append(key)\n",
    "            else:\n",
    "                break\n",
    "        ## include 'other':\n",
    "        tmp.append('other')\n",
    "        \n",
    "        if len(tmp) == 1: continue\n",
    "        \n",
    "        col_domain[c] = list(set(tmp))\n",
    "        print(f\"'{c}' domain size {len(col_domain[c])}\")\n",
    "                \n",
    "    return col_domain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## in the original 6G data, there are total 40428967 samples including:\n",
    "## click == 1: 6865066\n",
    "## click == 0: 33563901\n",
    "\n",
    "## we require that for each column, say 'banner_pos', each possible value of this columns\n",
    "## should contain no less than 1% of the total 0 or 1 label in train_df\n",
    "thresh0 = int( int( 2000000 / 40428967 * 33563901 ) / 100 )  \n",
    "thresh1 = int( int( 2000000 / 40428967 * 6865066 ) / 100 )\n",
    "\n",
    "print(f\"Threshold for label 0 and 1: {thresh0}, {thresh1}\")\n",
    "\n",
    "col_domain = choose_domain_by_col(train_df, tolerated_cols, target_cols, thresh0, thresh1)\n",
    "\n",
    "#for key, lst in col_domain.items():\n",
    "#    print(f\"'{key}' domain size {len(lst)}: \", lst)\n",
    "#    print(f\"'{key}' domain size {len(lst)}\")\n",
    "\n",
    "print(f\"Total number of features: {sum([len(lst) for _, lst in col_domain.items()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define funtion to check column 0-1 distribution:\n",
    "#train_df.query(\"click == 0\")['device_id'].value_counts()\n",
    "\n",
    "def col_01_check(col_name):\n",
    "    tmp_0 = train_df.query(\"click == 1\")[col_name].value_counts()\n",
    "    tmp_1 = train_df.query(\"click == 0\")[col_name].value_counts()\n",
    "    tmp_count = pd.concat([tmp_0, tmp_1], axis=1, sort=False)\n",
    "    tmp_count.columns = [col_name+'_0_count', col_name+'_1_count']\n",
    "    print(tmp_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_01_check('site_category')\n",
    "col_01_check('device_id')\n",
    "col_01_check('device_ip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, lst in col_domain.items():\n",
    "    print(f\"'{key}' domain size {len(lst)}: \", lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now need to transfer train_df data type to strings for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "import pyspark.sql.types as SparkType\n",
    "\n",
    "transfer_to_string = udf(lambda s: int(s), SparkType.StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df = train_df.withColumn('int_hour', get_hour('hour')).drop('hour')\n",
    "\n",
    "#df[[\"a\", \"b\"]] = df[[\"a\", \"b\"]].apply(str)\n",
    "\n",
    "## define function to check column by column if the sample should be descarded:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#col_list = list(train_df.columns)\n",
    "#for i in range(2000000):\n",
    "#    print(i)\n",
    "#    train_df.loc[i] = \n",
    "\n",
    "train_df_copy = pd.DataFrame(columns=list(train_df.columns))\n",
    "\n",
    "for idx, row in train_df.iterrows():\n",
    "    train_df_copy.loc[idx] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_copy.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_df['click'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now need to do transformation for each row in train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(col_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the whole domain for the target columns::\n",
    "target_domain = []\n",
    "for _, lst in col_domain.items(): target_domain += lst\n",
    "target_domain = set(target_domain)\n",
    "print(f\"Size of the target domain: {len(target_domain)}\")\n",
    "#print(target_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxes = set(range(2000000))\n",
    "for col in target_cols:\n",
    "    true_false_list = list(train_df[col].isin(target_domain))\n",
    "    print(f\"Checking {len(true_false_list)} rows for column: {col}\")\n",
    "    idxes = set([i for i in range(len(true_false_list)) if true_false_list[i] == True]).intersection(idxes)\n",
    "idxes = sorted(list(idxes))\n",
    "print(f\"How many samples left: {len(idxes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in sample_df.columns:\n",
    "    print(col, sample_df[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = train_df.iloc[idxes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in sample_df.columns:\n",
    "    print(col, sample_df[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_df.drop('device_id', axis=1, inplace=True)\n",
    "#sample_df.drop('device_ip', axis=1, inplace=True)\n",
    "sample_df.drop('C1', axis=1, inplace=True)\n",
    "sample_df.drop('device_type', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dum_col = set(sample_df.columns) - {'click'}\n",
    "sample_df = pd.get_dummies(sample_df, columns=list(dum_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now we can do vectorizer pipline or maybe try hasing first?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_columns(self):\n",
    "    \n",
    "    list_columns = self.columns\n",
    "    new_col_suffix = '_int'\n",
    "    for i in range(0,len(list_columns)):\n",
    "        if list_columns[i] == 'click': continue\n",
    "        self[list_columns[i]+new_col_suffix] = self[list_columns[i]].map( lambda  x: hash(x))\n",
    "        self.drop([list_columns[i]],inplace=True,axis=1)\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = hash_columns(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = train_df.drop('click', axis=1)\n",
    "#Y_train = train_df.click\n",
    "#X_train.dtypes\n",
    "\n",
    "pre_X = train_df.loc[:, train_df.columns != 'click']\n",
    "pre_Y = train_df.click.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install lightgbm\n",
    "\n",
    "#!conda install -c conda-forge lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "#create lightgbm dataset\n",
    "mask = np.random.rand(len(pre_X)) < 0.8\n",
    "\n",
    "train_X, train_Y = pre_X[mask], pre_Y[mask]\n",
    "test_X, test_Y = pre_X[~mask], pre_Y[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(train_X, train_Y)\n",
    "lgb_test = lgb.Dataset(test_X, test_Y, reference = lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model parameters:\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': { 'binary_logloss'},\n",
    "    'num_leaves': 32, # default leave amount for each tree\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.7, # will select 70% features before training each tree\n",
    "    #'bagging_fraction': 0.3, #feature_fraction, but this will random select part of data\n",
    "    #'bagging_freq': 5, #  perform bagging at every 5 iteration\n",
    "    'verbose': 1\n",
    "}\n",
    "# valid_sets = [valid_set, train_set], valid_names = [‘eval’, ‘train’]\n",
    "\n",
    "# model training:\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=10000,\n",
    "                valid_sets  = [lgb_train, lgb_test],\n",
    "                valid_names = ['train', 'eval'],\n",
    "                early_stopping_rounds=500,\n",
    "                verbose_eval = 1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(gbm.best_score)\n",
    "#print(gbm.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(lgb_test)\n",
    "pred_prob = gbm.predict(test_X)\n",
    "pred = pred_prob > 0.5\n",
    "print(sum(pred)/len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy, precision and recall\n",
    "def compute_scores(conf_matrix):\n",
    "    \n",
    "    tn, fp, fn, tp = conf_matrix[0][0], conf_matrix[0][1], conf_matrix[1][0], conf_matrix[1][1]\n",
    "    \n",
    "    accuracy  = (tp + tn) / (tp + fp + fn + tn)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    \n",
    "    print (\"Accuracy is: %0.3f\" % accuracy)\n",
    "    print (\"precision is: %0.3f\" % precision)\n",
    "    print (\"recall is: %0.3f\" % recall)\n",
    "\n",
    "conf_matrix = confusion_matrix(test_Y, pred)\n",
    "compute_scores(conf_matrix)\n",
    "print(\"AUC is: \", roc_auc_score(test_Y, pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import metrics\n",
    "\n",
    "# define function for plotting curve:\n",
    "def plot_curve(model_name, x, name1, y1, name2, y2, name3, y3):\n",
    "    plt.plot(x, y1, lw = 2, label = name1)\n",
    "    plt.plot(x, y2, lw = 2, label = name2 )\n",
    "    plt.plot(x, y3, lw = 2, label = name3)\n",
    "    plt.xlabel('Model threshold')\n",
    "    plt.ylabel('Model score')\n",
    "    plt.title('Model score vs threshold for ' + model_name)\n",
    "    plt.legend(loc='lower center')\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    return\n",
    "\n",
    "## initialize accuracy, precision and recall:\n",
    "accuracy, precision, recall = [], [], []\n",
    "## compute probability of positive case:\n",
    "pred_prob = gbm.predict(test_X)\n",
    "## compute fpr, tpr and threshold:\n",
    "fpr, tpr, thresh = roc_curve(test_Y, pred_prob)\n",
    "for j in range(len(thresh)):\n",
    "    accuracy.append(   accuracy_score(test_Y, pred_prob >= thresh[j]) )\n",
    "    precision.append( precision_score(test_Y, pred_prob >= thresh[j]) )\n",
    "    recall.append(       recall_score(test_Y, pred_prob >= thresh[j]) )\n",
    "\n",
    "    \n",
    "accuracy, precision, recall = np.asarray(accuracy), np.asarray(precision), np.asarray(recall)\n",
    "plot_curve( \"lightgbm\", thresh[1:], \"Accucary\", accuracy[1:], \"Precision\", precision[1:], \"Recall\", recall[1:] )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train-test split: reserve 20% for testing\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, Y_train, Y_test =  train_test_split(preX, preY, test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import models:\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC \n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Logistic Regression\n",
    "classifier_LR = LogisticRegression()\n",
    "\n",
    "# K Nearest Neighbors\n",
    "#classifier_KNN = KNeighborsClassifier()\n",
    "\n",
    "# Random Forest\n",
    "classifier_RF = RandomForestClassifier(random_state = 0)\n",
    "\n",
    "## support vector machine:\n",
    "classifier_SVM = SVC()\n",
    "\n",
    "## Gradient boosting:\n",
    "classifier_GB = XGBClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 5-fold Cross Validation to get the accuracy for all three models\n",
    "model_names = [\"Logistic Regression\", \"Random Forest\", \"Support Vector Machine\", \"Gradient Boosting\"]\n",
    "model_list = [classifier_LR, classifier_RF, classifier_SVM, classifier_GB]\n",
    "\n",
    "for i in range(len(model_list)):\n",
    "    classifier = model_list[i]\n",
    "    cv_score = model_selection.cross_val_score(classifier, train_X, train_Y, cv=5)\n",
    "    print(\"Accuracy for \" + model_names[i] + \" is: \", cv_score.mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [best_models[0], best_models[3]]\n",
    "model_names = [\"Random Forest\", \"Gradient Boosting\"]\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(10,4))\n",
    "\n",
    "# define function for plotting curve:\n",
    "def plot_curve(model_name, ax, x, name_y1, y1, name_y2, y2, name_y3, y3):\n",
    "    ax.plot(x, y1, lw = 2, label = name_y1)\n",
    "    ax.plot(x, y2, lw = 2, label = name_y2 )\n",
    "    ax.plot(x, y3, lw = 2, label = name_y3)\n",
    "    ax.set_xlabel('Model threshold')\n",
    "    ax.set_ylabel('Model score')\n",
    "    ax.set_title('Model score vs threshold for ' + model_name)\n",
    "    ax.legend(loc='lower center')\n",
    "    ax.set_xlim([-0.05, 1.05])\n",
    "    return\n",
    "\n",
    "for i in range(len(models)):\n",
    "    ## pick up models and model names:\n",
    "    model, model_name = models[i], model_names[i]\n",
    "    ## initialize accuracy, precision and recall:\n",
    "    accuracy, precision, recall = [], [], []\n",
    "    ## compute probability of positive case:\n",
    "    pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "    ## compute fpr, tpr and threshold:\n",
    "    fpr, tpr, thresh = roc_curve(Y_test, pred_prob)\n",
    "    for j in range(len(thresh)):\n",
    "        accuracy.append(   accuracy_score(Y_test, pred_prob >= thresh[j]) )\n",
    "        precision.append( precision_score(Y_test, pred_prob >= thresh[j]) )\n",
    "        recall.append(       recall_score(Y_test, pred_prob >= thresh[j]) )\n",
    "    \n",
    "    accuracy, precision, recall = np.asarray(accuracy), np.asarray(precision), np.asarray(recall)\n",
    "    plot_curve( model_name, axes[i], thresh[1:],\\\n",
    "                \"Accucary\", accuracy[1:],\\\n",
    "                \"Precision\", precision[1:],\\\n",
    "                \"Recall\", recall[1:] )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
