{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Supervised Learning Project.ipynb","version":"0.3.2","provenance":[{"file_id":"1BtyDGHRJSmlyi29CPUH8ZNmzh-j0eg3d","timestamp":1545526424684}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"R88Ms0MTi0Ma","colab_type":"text"},"cell_type":"markdown","source":["# User Churn Prediction"]},{"metadata":{"id":"WA6lL1fni0Mb","colab_type":"text"},"cell_type":"markdown","source":["**In** this project, we use supervised learning models to identify customers who are likely to stop using service in the future. Furthermore, we will analyze top factors that influence user retention."]},{"metadata":{"id":"bO94-bXZi0Md","colab_type":"text"},"cell_type":"markdown","source":["## Contents"]},{"metadata":{"id":"SIvRSRqAi0Md","colab_type":"text"},"cell_type":"markdown","source":["<ul>\n","<li>[Part 1: Data Exploration](#Part-1:-Data-Exploration)\n","<li>[Part 2: Feature Preprocessing](#Part-2:-Feature-Preprocessing)\n","<li>[Part 3: Model Training and Results Evaluation](#Part-3:-Model-Training-and-Result-Evaluation)\n","<li>[Part 4: Feature Selection](#Part-4:-Feature-Selection)\n","</ul>"]},{"metadata":{"id":"TUoI2S7Bi6iR","colab_type":"text"},"cell_type":"markdown","source":["# Part 0: Setup Google Drive Environment"]},{"metadata":{"id":"neechzbWi7rV","colab_type":"code","colab":{}},"cell_type":"code","source":["# method 1 install pydrive to load data\n","!pip install -U -q PyDrive\n","\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UScKyL2TjARW","colab_type":"code","colab":{}},"cell_type":"code","source":["link = 'https://drive.google.com/open?id=1BmXe8XIPvbghz7kMEjmt9vBX8LZbX4Jq'\n","fluff, id = link.split('=')\n","file = drive.CreateFile({'id':id}) # replace the id with id of file you want to access\n","file.GetContentFile('churn.all')  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"nK7A1qhYSDxM","colab_type":"code","colab":{}},"cell_type":"code","source":["import pandas as pd\n","\n","df1 = pd.read_csv('churn.all')\n","df1.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vhMVchpMPjRc","colab_type":"code","colab":{}},"cell_type":"code","source":["# method 2 upload from local\n","from google.colab import files\n","uploaded = files.upload()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"M31NVxpbPvS9","colab_type":"code","colab":{}},"cell_type":"code","source":["import io\n","import pandas as pd\n","\n","df2 = pd.read_csv(io.BytesIO(uploaded['uk_rain_2014.csv']))\n","df2.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ikYHWOnYfKPM","colab_type":"text"},"cell_type":"markdown","source":["**Homework 0: Use the recommended way to load data.**"]},{"metadata":{"id":"1iLCfrlpe-pV","colab_type":"code","cellView":"form","colab":{}},"cell_type":"code","source":["#@title Homework 0\n","####\n","## Your Code\n","####\n","#import pandas as pd\n","#file_id='1BmXe8XIPvbghz7kMEjmt9vBX8LZbX4Jq'\n","#link='https://drive.google.com/uc?export=download&id={FILE_ID}'\n","#csv_url=link.format(FILE_ID=file_id)\n","#my_data = pd.read_csv(csv_url)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KbCamNSoLcuX","colab_type":"code","colab":{}},"cell_type":"code","source":["my_data.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"a6bG_gAPi0Me","colab_type":"text"},"cell_type":"markdown","source":["# Part 1: Data Exploration"]},{"metadata":{"id":"bspx2K6fi0Me","colab_type":"text"},"cell_type":"markdown","source":["### Part 1.1: Understand the Raw Dataset"]},{"metadata":{"id":"kuTHKjk-i0Mf","colab_type":"code","colab":{}},"cell_type":"code","source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","import pandas as pd\n","import numpy as np\n","import imblearn\n","# will show all the columns\n","pd.set_option('display.max_columns', None)\n","\n","churn_df = pd.read_csv('churn.all')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CtUqK6j1fhDN","colab_type":"code","cellView":"both","colab":{}},"cell_type":"code","source":["#@title *Bonus (不需要掌握): The Iris dataset in sklearn*\n","from sklearn import datasets\n","iris = datasets.load_iris()\n","\n","print(type(iris)) # bunch like dictionary\n","print(iris.keys())\n","\n","X = iris.data\n","y = iris.target\n","df = pd.DataFrame(X, columns=iris.feature_names)\n","print(df.head())"],"execution_count":0,"outputs":[]},{"metadata":{"scrolled":true,"id":"hHNZRs2Ti0Mi","colab_type":"code","colab":{}},"cell_type":"code","source":["churn_df.head()\n","# churn_df.info()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"C99Z9b7ai0Mm","colab_type":"code","colab":{}},"cell_type":"code","source":["print (\"Num of rows: \" + str(churn_df.shape[0])) # row count\n","print (\"Num of columns: \" + str(churn_df.shape[1])) # col count"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OCglmJ9Oi0Mo","colab_type":"text"},"cell_type":"markdown","source":["### Part 1.2: Data cleaning"]},{"metadata":{"id":"JxlrXRG3i0Mp","colab_type":"text"},"cell_type":"markdown","source":["Remove Extra Whitespace"]},{"metadata":{"scrolled":true,"id":"2Vf8iYmWi0Mq","colab_type":"code","colab":{}},"cell_type":"code","source":["# check categorical feature\n","churn_df['voice_mail_plan'][0]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3lpwxvQfi0Mt","colab_type":"code","colab":{}},"cell_type":"code","source":["# remove the heading and trailing whitespaces\n","churn_df['voice_mail_plan'] = churn_df['voice_mail_plan'].map(lambda x: x.strip())\n","churn_df['intl_plan'] = churn_df['intl_plan'].map(lambda x: x.strip())\n","churn_df['churned'] = churn_df['churned'].map(lambda x: x.strip())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kcyHhHKHZN2p","colab_type":"code","colab":{}},"cell_type":"code","source":["# check the categorical feature after manipulation\n","churn_df['voice_mail_plan'][0]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SsAbAjhvi0Mx","colab_type":"text"},"cell_type":"markdown","source":["### Part 1.3:  Understand the features"]},{"metadata":{"scrolled":false,"id":"rJ0AdxwLi0Mz","colab_type":"code","colab":{}},"cell_type":"code","source":["# check the feature distribution\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","sns.distplot(churn_df['total_intl_charge'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4DKTTdB6i0M2","colab_type":"code","colab":{}},"cell_type":"code","source":["# correlations between all the features\n","corr = churn_df[[\"account_length\", \"number_vmail_messages\", \"total_day_minutes\",\n","                    \"total_day_calls\", \"total_day_charge\", \"total_eve_minutes\",\n","                    \"total_eve_calls\", \"total_eve_charge\", \"total_night_minutes\",\n","                    \"total_night_calls\", \"total_intl_minutes\", \"total_intl_calls\",\n","                    \"total_intl_charge\"]].corr()\n","\n","# show heapmap of correlations\n","sns.heatmap(corr)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1qfEnNW_i0M5","colab_type":"code","colab":{}},"cell_type":"code","source":["# check the actual values of correlations\n","corr"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aFa4d6t3i0NH","colab_type":"text"},"cell_type":"markdown","source":["# Part 2: Feature Preprocessing"]},{"metadata":{"id":"wtjI61m6i0M8","colab_type":"code","colab":{}},"cell_type":"code","source":["# calculate two features correlation\n","from scipy.stats import pearsonr\n","print (pearsonr(churn_df['total_day_minutes'], churn_df['number_vmail_messages'])[0])"],"execution_count":0,"outputs":[]},{"metadata":{"scrolled":true,"id":"pxtf6XoJi0NI","colab_type":"code","colab":{}},"cell_type":"code","source":["churn_df.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4ec5r_Qdi0NL","colab_type":"code","colab":{}},"cell_type":"code","source":["# Get ground truth data\n","y = np.where(churn_df['churned'] == 'True.',1,0)\n","\n","# Drop some useless columns\n","to_drop = ['state','area_code','phone_number','churned']\n","churn_feat_space = churn_df.drop(to_drop, axis=1)\n","\n","# yes and no have to be converted to boolean values\n","yes_no_cols = [\"intl_plan\",\"voice_mail_plan\"]\n","churn_feat_space[yes_no_cols] = churn_feat_space[yes_no_cols] == 'yes'\n","\n","X = churn_feat_space"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7cWYAEiNJj_T","colab_type":"code","colab":{}},"cell_type":"code","source":["X"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rzCo_GC97rGd","colab_type":"code","colab":{}},"cell_type":"code","source":["# check the propotion of y = 1\n","print(y.sum() / y.shape * 100)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oNsZwmWxi0NP","colab_type":"text"},"cell_type":"markdown","source":["#### Homework 1: Can you add catogorical features, e.g. state, into your feature matrix?"]},{"metadata":{"id":"JMTIEpY7IfPp","colab_type":"text"},"cell_type":"markdown","source":["Read more for handling [categorical feature](https://github.com/scikit-learn-contrib/categorical-encoding)"]},{"metadata":{"id":"MrsjiqTwi0NQ","colab_type":"code","cellView":"form","colab":{}},"cell_type":"code","source":["#@title Homework 1\n","####\n","## Your Code\n","####\n","\n","#to_drop_hw1 = ['area_code','phone_number','churned']\n","#churn_feat_space_hw1 = churn_df.drop(to_drop_hw1, axis=1)\n","\n","# yes and no have to be converted to boolean values\n","#yes_no_cols = [\"intl_plan\",\"voice_mail_plan\"]\n","#churn_feat_space_hw1[yes_no_cols] = churn_feat_space_hw1[yes_no_cols] == 'yes'\n","\n","#churn_feat_space_hw1 = pd.get_dummies(churn_feat_space_hw1, columns=['state'])\n","\n","#churn_feat_space_hw1.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"q3x9ySX_i0Nd","colab_type":"text"},"cell_type":"markdown","source":["# Part 3: Model Training and Result Evaluation"]},{"metadata":{"id":"77OjmSl9i0Nf","colab_type":"text"},"cell_type":"markdown","source":["### Part 3.1: Split dataset"]},{"metadata":{"id":"Uay8Md5li0Nh","colab_type":"code","colab":{}},"cell_type":"code","source":["# Splite data into training and testing\n","from sklearn import model_selection\n","\n","# Reserve 20% for testing\n","X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2)\n","\n","print('training data has %d observation with %d features'% X_train.shape)\n","print('test data has %d observation with %d features'% X_test.shape)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JuPhtUkJi0NW","colab_type":"code","colab":{}},"cell_type":"code","source":["# Scale the data, using standardization\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"c4UTtCQTi0Nl","colab_type":"text"},"cell_type":"markdown","source":["### Part 3.2: Model Training and Selection"]},{"metadata":{"id":"EAhSxINLi0Nl","colab_type":"code","cellView":"code","colab":{}},"cell_type":"code","source":["#@title build models\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neighbors import KNeighborsClassifier \n","from sklearn.linear_model import LogisticRegression\n","\n","# Logistic Regression\n","classifier_logistic = LogisticRegression()\n","\n","# K Nearest Neighbors\n","classifier_KNN = KNeighborsClassifier()\n","\n","# Random Forest\n","classifier_RF = RandomForestClassifier()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Av0IRSoBQ3pe","colab_type":"code","colab":{}},"cell_type":"code","source":["# Train the model\n","classifier_logistic.fit(X_train, y_train)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EiLuzUDJRBNi","colab_type":"code","colab":{}},"cell_type":"code","source":["# Prediction of test data\n","classifier_logistic.predict(X_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XjMV04mKRJ30","colab_type":"code","colab":{}},"cell_type":"code","source":["# Accuracy of test data\n","classifier_logistic.score(X_test, y_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1OCgNSNri0Nn","colab_type":"code","colab":{}},"cell_type":"code","source":["# Use 5-fold Cross Validation to get the accuracy for different models\n","model_names = ['Logistic Regression','KNN','Random Forest']\n","model_list = [classifier_logistic, classifier_KNN, classifier_RF]\n","count = 0\n","\n","for classifier in model_list:\n","    cv_score = model_selection.cross_val_score(classifier, X_train, y_train, cv=5)\n","    # cprint(cv_score)\n","    print('Model accuracy of %s is: %.3f'%(model_names[count],cv_score.mean()))\n","    count += 1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"G1GCzaPxi0Np","colab_type":"text"},"cell_type":"markdown","source":["#### Homework 2: Can you do prediction with SVM model?"]},{"metadata":{"id":"yxmKTdahi0Nq","colab_type":"code","colab":{},"cellView":"form"},"cell_type":"code","source":["#@title Homework 2\n","####\n","## Your Code\n","####\n","# SVC\n","#from sklearn.svm import SVC \n","\n","#classifier_SVC = SVC()\n","\n","#cv_score = model_selection.cross_val_score(classifier_SVC, X_train, y_train, cv=5)\n","#print('Model accuracy of SVM is: %.3f'%(cv_score.mean()))\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7J-23z78i0Ns","colab_type":"text"},"cell_type":"markdown","source":["### (Optional) Part 3.3: Use Grid Search to Find Optimal Hyperparameters"]},{"metadata":{"id":"Hpe9PEAAi0Nt","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV\n","\n","# helper function for printing out grid search results \n","def print_grid_search_metrics(gs):\n","    print (\"Best score: %0.3f\" % gs.best_score_)\n","    print (\"Best parameters set:\")\n","    best_parameters = gs.best_params_\n","    for param_name in sorted(parameters.keys()):\n","        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qvYo9I5Ti0Nv","colab_type":"text"},"cell_type":"markdown","source":["#### Part 3.3.1: Find Optimal Hyperparameters - LogisticRegression"]},{"metadata":{"scrolled":true,"id":"wOc48syxi0Nx","colab_type":"code","colab":{}},"cell_type":"code","source":["# Possible hyperparamter options for Logistic Regression Regularization\n","# Penalty is choosed from L1 or L2\n","# C is the lambda value(weight) for L1 and L2\n","parameters = {\n","    'penalty':('l1', 'l2'), \n","    'C':(1, 5, 10)\n","}\n","Grid_LR = GridSearchCV(LogisticRegression(),parameters, cv=5)\n","Grid_LR.fit(X_train, y_train)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nN5rU0e-i0N1","colab_type":"code","colab":{}},"cell_type":"code","source":["# the best hyperparameter combination\n","print_grid_search_metrics(Grid_LR)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TtkDsXgui0N3","colab_type":"code","colab":{}},"cell_type":"code","source":["# best model\n","best_LR_model = Grid_LR.best_estimator_"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9u9YFedOi0N6","colab_type":"text"},"cell_type":"markdown","source":["#### Part 3.3.2: Find Optimal Hyperparameters: KNN"]},{"metadata":{"id":"o78422XVi0N6","colab_type":"code","colab":{}},"cell_type":"code","source":["# Possible hyperparamter options for KNN\n","# Choose k\n","parameters = {\n","    'n_neighbors':[3,5,7,10] \n","}\n","Grid_KNN = GridSearchCV(KNeighborsClassifier(),parameters, cv=5)\n","Grid_KNN.fit(X_train, y_train)"],"execution_count":0,"outputs":[]},{"metadata":{"scrolled":true,"id":"ydaRZVAIi0N_","colab_type":"code","colab":{}},"cell_type":"code","source":["# best k\n","print_grid_search_metrics(Grid_KNN)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nKn_oKLSi0OB","colab_type":"text"},"cell_type":"markdown","source":["#### Part 3.3.3: Find Optimal Hyperparameters: Random Forest"]},{"metadata":{"id":"NniAZIPfi0OC","colab_type":"code","colab":{}},"cell_type":"code","source":["# Possible hyperparamter options for Random Forest\n","# Choose the number of trees\n","parameters = {\n","    'n_estimators' : [40,60,80]\n","}\n","Grid_RF = GridSearchCV(RandomForestClassifier(),parameters, cv=5)\n","Grid_RF.fit(X_train, y_train)"],"execution_count":0,"outputs":[]},{"metadata":{"scrolled":true,"id":"ScPiI-Bfi0OE","colab_type":"code","colab":{}},"cell_type":"code","source":["# best number of tress\n","print_grid_search_metrics(Grid_RF)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xJgfri_Mi0OG","colab_type":"code","colab":{}},"cell_type":"code","source":["# best random forest\n","best_RF_model = Grid_RF.best_estimator_"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xxDAOrGIi0OI","colab_type":"text"},"cell_type":"markdown","source":["### Part 3.4: Model Evaluation - Confusion Matrix (Precision, Recall, Accuracy)\n","\n","class of interest as positive\n","\n","TP: correctly labeled real churn\n","\n","Precision(PPV, positive predictive value): tp / (tp + fp);\n","Total number of true predictive churn divided by the total number of predictive churn;\n","High Precision means low fp, not many return users were predicted as churn users. \n","\n","\n","Recall(sensitivity, hit rate, true positive rate): tp / (tp + fn)\n","Predict most postive or churn user correctly. High recall means low fn, not many churn users were predicted as return users."]},{"metadata":{"id":"o-tP94iFi0OI","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","\n","# calculate accuracy, precision and recall\n","def cal_evaluation(classifier, cm):\n","    tn = cm[0][0]\n","    fp = cm[0][1]\n","    fn = cm[1][0]\n","    tp = cm[1][1]\n","    accuracy  = (tp + tn) / (tp + fp + fn + tn + 0.0)\n","    precision = tp / (tp + fp + 0.0)\n","    recall = tp / (tp + fn + 0.0)\n","    print (classifier)\n","    print (\"Accuracy is: %0.3f\" % accuracy)\n","    print (\"precision is: %0.3f\" % precision)\n","    print (\"recall is: %0.3f\" % recall)\n","\n","# print out confusion matrices\n","def draw_confusion_matrices(confusion_matricies):\n","    class_names = ['Not','Churn']\n","    for cm in confusion_matrices:\n","        classifier, cm = cm[0], cm[1]\n","        cal_evaluation(classifier, cm)\n","        fig = plt.figure()\n","        ax = fig.add_subplot(111)\n","        cax = ax.matshow(cm, interpolation='nearest',cmap=plt.get_cmap('Reds'))\n","        plt.title('Confusion matrix for %s' % classifier)\n","        fig.colorbar(cax)\n","        ax.set_xticklabels([''] + class_names)\n","        ax.set_yticklabels([''] + class_names)\n","        plt.xlabel('Predicted')\n","        plt.ylabel('True')\n","        plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OpSGaN49i0OL","colab_type":"code","colab":{}},"cell_type":"code","source":["%matplotlib inline\n","\n","# Confusion matrix, accuracy, precison and recall for random forest and logistic regression\n","confusion_matrices = [\n","    (\"Random Forest\", confusion_matrix(y_test,best_RF_model.predict(X_test))),\n","    (\"Logistic Regression\", confusion_matrix(y_test,best_LR_model.predict(X_test))),\n","]\n","\n","draw_confusion_matrices(confusion_matrices)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OvHlyhPBi0OT","colab_type":"text"},"cell_type":"markdown","source":["### Part 3.4: Model Evaluation - ROC & AUC"]},{"metadata":{"id":"jx_3XkgKi0OW","colab_type":"text"},"cell_type":"markdown","source":["RandomForestClassifier, KNeighborsClassifier and LogisticRegression have predict_prob() function "]},{"metadata":{"id":"-Os_ZLTvi0OX","colab_type":"text"},"cell_type":"markdown","source":["#### Part 3.4.1: ROC of RF Model"]},{"metadata":{"id":"UypvQMVBi0OY","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.metrics import roc_curve\n","from sklearn import metrics\n","\n","# Use predict_proba to get the probability results of Random Forest\n","y_pred_rf = best_RF_model.predict_proba(X_test)[:, 1]\n","fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_rf)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"s3PR-PdPi0Ob","colab_type":"code","colab":{}},"cell_type":"code","source":["# ROC curve of Random Forest result\n","plt.figure(1)\n","plt.plot([0, 1], [0, 1], 'k--')\n","plt.plot(fpr_rf, tpr_rf, label='RF')\n","plt.xlabel('False positive rate')\n","plt.ylabel('True positive rate')\n","plt.title('ROC curve - RF model')\n","plt.legend(loc='best')\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"R89IUMYDi0Oe","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn import metrics\n","\n","# AUC score\n","metrics.auc(fpr_rf,tpr_rf)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-1DVqnJVi0Oh","colab_type":"text"},"cell_type":"markdown","source":["#### Part 3.4.1: ROC of LR Model"]},{"metadata":{"id":"t-q5XJPoi0Oi","colab_type":"code","colab":{}},"cell_type":"code","source":["# Use predict_proba to get the probability results of Logistic Regression\n","y_pred_lr = best_LR_model.predict_proba(X_test)[:, 1]\n","fpr_lr, tpr_lr, _ = roc_curve(y_test, y_pred_lr)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KZSrN-1Mi0Ok","colab_type":"code","colab":{}},"cell_type":"code","source":["# ROC Curve\n","plt.figure(1)\n","plt.plot([0, 1], [0, 1], 'k--')\n","plt.plot(fpr_lr, tpr_lr, label='LR')\n","plt.xlabel('False positive rate')\n","plt.ylabel('True positive rate')\n","plt.title('ROC curve - LR Model')\n","plt.legend(loc='best')\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LHAyxishi0On","colab_type":"code","colab":{}},"cell_type":"code","source":["# AUC score\n","metrics.auc(fpr_lr,tpr_lr)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gHHurD8Ii0Oq","colab_type":"text"},"cell_type":"markdown","source":["# Part 4: Feature Selection"]},{"metadata":{"id":"dSx4TPO-i0Or","colab_type":"text"},"cell_type":"markdown","source":["### Part 4.1:  Logistic Regression Model - Feature Selection Discussion "]},{"metadata":{"id":"BtLHUixoi0Ot","colab_type":"text"},"cell_type":"markdown","source":["The corelated features that we are interested in: (total_day_minutes, total_day_charge), (total_eve_minutes, total_eve_charge), (total_intl_minutes, total_intl_charge)."]},{"metadata":{"scrolled":true,"id":"cQaXOIsUi0Ou","colab_type":"code","colab":{}},"cell_type":"code","source":["# add L1 regularization to logistic regression\n","# check the coef for feature selection\n","scaler = StandardScaler()\n","X_l1 = scaler.fit_transform(X)\n","LRmodel_l1 = LogisticRegression(penalty=\"l1\", C = 0.1)\n","LRmodel_l1.fit(X_l1, y)\n","LRmodel_l1.coef_[0]\n","print (\"Logistic Regression (L1) Coefficients\")\n","for k,v in sorted(zip(map(lambda x: round(x, 4), LRmodel_l1.coef_[0]), \\\n","                      churn_feat_space.columns), key=lambda k_v:(-abs(k_v[0]),k_v[1])):\n","    print (v + \": \" + str(k))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"majifZZqi0O9","colab_type":"code","colab":{}},"cell_type":"code","source":["# add L2 regularization to logistic regression\n","# check the coef for feature selection\n","scaler = StandardScaler()\n","X_l2 = scaler.fit_transform(X)\n","LRmodel_l2 = LogisticRegression(penalty=\"l2\", C = 5)\n","LRmodel_l2.fit(X_l2, y)\n","LRmodel_l2.coef_[0]\n","print (\"Logistic Regression (L2) Coefficients\")\n","for k,v in sorted(zip(map(lambda x: round(x, 4), LRmodel_l2.coef_[0]), \\\n","                      churn_feat_space.columns), key=lambda k_v:(-abs(k_v[0]),k_v[1])):\n","    print (v + \": \" + str(k))\n","  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"uqs41ydLi0O_","colab_type":"text"},"cell_type":"markdown","source":["### Part 4.2:  Random Forest Model - Feature Importance Discussion"]},{"metadata":{"id":"MPxUM2lei0PA","colab_type":"code","colab":{}},"cell_type":"code","source":["# check feature importance of random forest for feature selection\n","forest = RandomForestClassifier()\n","forest.fit(X, y)\n","\n","importances = forest.feature_importances_\n","\n","# Print the feature ranking\n","print(\"Feature importance ranking by Random Forest Model:\")\n","for k,v in sorted(zip(map(lambda x: round(x, 4), importances), churn_feat_space.columns), reverse=True):\n","    print (v + \": \" + str(k))"],"execution_count":0,"outputs":[]}]}