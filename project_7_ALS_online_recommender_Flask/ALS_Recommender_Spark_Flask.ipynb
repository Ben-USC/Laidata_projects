{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: ben\n",
    "date: 2019-11-11\n",
    "\"\"\"\n",
    "\n",
    "### define urls for the dataset\n",
    "small_data_url = \"http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
    "full_data_url = \"http://files.grouplens.org/datasets/movielens/ml-latest.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define download locations:\n",
    "import os\n",
    "data_path = os.path.join(\".\", \"data\")\n",
    "small_data_path = os.path.join(data_path, \"ml-latest-small.zip\")\n",
    "full_data_path = os.path.join(data_path, \"ml-latest.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## download the zip files:\n",
    "import urllib.request\n",
    "small_data = urllib.request.urlretrieve(small_data_url, small_data_path)\n",
    "full_data = urllib.request.urlretrieve(full_data_url, full_data_path)\n",
    "\n",
    "### unzip the downloaded files\n",
    "import zipfile\n",
    "with zipfile.ZipFile(small_data_path, \"r\") as t:\n",
    "    t.extractall(data_path)\n",
    "with zipfile.ZipFile(full_data_path, \"r\") as t:\n",
    "    t.extractall(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### now we can parse and load the data files\n",
    "##from pyspark.sql import SparkSession\n",
    "##sc = SparkSession.builder.appName(\"ALS\").getOrCreate()\n",
    "\n",
    "from pyspark.context import SparkContext\n",
    "SparkContext.setSystemProperty('spark.executor.memory', '5g')\n",
    "sc =  SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId,movieId,rating,timestamp\n"
     ]
    }
   ],
   "source": [
    "small_ratings = os.path.join(data_path, \"ml-latest-small\", \"ratings.csv\")\n",
    "small_ratings_rdd = sc.textFile(small_ratings)\n",
    "small_header = small_ratings_rdd.take(1)[0]\n",
    "print(small_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_ratings_rdd = (small_ratings_rdd.filter(lambda l: l != small_header)\n",
    "                     .map(lambda l: l.split(\",\"))\n",
    "                     .map(lambda l: (l[0], l[1], l[2]) ).cache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1', '1', '4.0'), ('1', '3', '4.0'), ('1', '6', '4.0')]\n"
     ]
    }
   ],
   "source": [
    "print(small_ratings_rdd.take(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.txt  links.csv   movies.csv  ratings.csv tags.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./data/ml-latest-small/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movieId,title,genres\n"
     ]
    }
   ],
   "source": [
    "small_movies = os.path.join(data_path, \"ml-latest-small\", \"movies.csv\")\n",
    "small_movies_rdd = sc.textFile(small_movies)\n",
    "small_header = small_movies_rdd.take(1)[0]\n",
    "print(small_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_movies_rdd = (small_movies_rdd.filter(lambda l: l!= small_header)\n",
    "                   .map(lambda l: l.split(\",\"))\n",
    "                   .map(lambda l: (l[0], l[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1', 'Toy Story (1995)'), ('2', 'Jumanji (1995)'), ('3', 'Grumpier Old Men (1995)')]\n"
     ]
    }
   ],
   "source": [
    "print(small_movies_rdd.take(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rdd, valid_rdd, hold_rdd = small_ratings_rdd.randomSplit([6,2,2], seed=16807)\n",
    "valid_for_pred = valid_rdd.map(lambda r: (int(r[0]), int(r[1])))\n",
    "hold_for_pred = hold_rdd.map(lambda r: (int(r[0]), int(r[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model with rank = 4 & lambda = 0.02 has MSE:  1.0229567024546342\n",
      "model with rank = 6 & lambda = 0.02 has MSE:  1.0608889180004513\n",
      "model with rank = 8 & lambda = 0.02 has MSE:  1.0985095995771081\n",
      "model with rank = 10 & lambda = 0.02 has MSE:  1.1167148740192265\n",
      "model with rank = 12 & lambda = 0.02 has MSE:  1.144699318657436\n",
      "model with rank = 4 & lambda = 0.05 has MSE:  0.956813493758704\n",
      "model with rank = 6 & lambda = 0.05 has MSE:  0.9761115969435162\n",
      "model with rank = 8 & lambda = 0.05 has MSE:  0.9837170754784507\n",
      "model with rank = 10 & lambda = 0.05 has MSE:  0.995090709315019\n",
      "model with rank = 12 & lambda = 0.05 has MSE:  1.0038294682861604\n",
      "model with rank = 4 & lambda = 0.1 has MSE:  0.9095306483375436\n",
      "model with rank = 6 & lambda = 0.1 has MSE:  0.9144034013919901\n",
      "model with rank = 8 & lambda = 0.1 has MSE:  0.9155277182121414\n",
      "model with rank = 10 & lambda = 0.1 has MSE:  0.9172446979073086\n",
      "model with rank = 12 & lambda = 0.1 has MSE:  0.9176534860971569\n",
      "model with rank = 4 & lambda = 0.2 has MSE:  0.8961095010405554\n",
      "model with rank = 6 & lambda = 0.2 has MSE:  0.8957227628522765\n",
      "model with rank = 8 & lambda = 0.2 has MSE:  0.8962839909839723\n",
      "model with rank = 10 & lambda = 0.2 has MSE:  0.8965166577958794\n",
      "model with rank = 12 & lambda = 0.2 has MSE:  0.8957130624187942\n",
      "Therefore, the best model has rank 12, lambda 0.2, and MSE: 0.8957130624187942\n"
     ]
    }
   ],
   "source": [
    "### hyperparameters for ALS model\n",
    "## rank: number of latent factors in the model.\n",
    "## lambda: regularization parameter\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "import math\n",
    "\n",
    "ranks = [4, 6, 8, 10, 12]\n",
    "itr = 10\n",
    "lamdas = [0.02, 0.05, 0.1, 0.2]\n",
    "tolerance = 0.02\n",
    "min_MSE = float(\"inf\")\n",
    "\n",
    "best_rank = best_lambda = 0\n",
    "\n",
    "for lamda in lamdas:\n",
    "    for rank in ranks:\n",
    "        model = ALS.train(train_rdd, rank, itr, seed = 123, lambda_ = lamda)\n",
    "        preds = model.predictAll(valid_for_pred).map(lambda r: ((int(r[0]), int(r[1])), float(r[2])))\n",
    "        rates_and_preds = valid_rdd.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(preds)\n",
    "        error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0]-r[1][1])**2).mean())\n",
    "        print(f\"model with rank = {rank} & lambda = {lamda} has MSE: \", error)\n",
    "        if error < min_MSE:\n",
    "            min_MSE = error\n",
    "            best_rank, best_lambda = rank, lamda\n",
    "\n",
    "print(f\"Therefore, the best model has rank {best_rank}, lambda {best_lambda}, and MSE: {min_MSE}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rank, best_lambda = 12, 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of the best model on the holdout set: 0.9029795839647352\n"
     ]
    }
   ],
   "source": [
    "model = ALS.train(train_rdd, best_rank, itr, seed=16807, lambda_ = best_lambda)\n",
    "preds = model.predictAll(hold_for_pred).map(lambda r: ((int(r[0]), int(r[1])), float(r[2])))\n",
    "rates_and_preds = hold_rdd.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(preds)\n",
    "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "\n",
    "print(f\"MSE of the best model on the holdout set: {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now use the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 307, 3.5), (1, 481, 3.5), (1, 1091, 1.5)]\n"
     ]
    }
   ],
   "source": [
    "full_ratings = os.path.join(data_path, \"ml-latest\", \"ratings.csv\")\n",
    "full_ratings_rdd = sc.textFile(full_ratings)\n",
    "full_header = full_ratings_rdd.take(1)[0]\n",
    "full_ratings_rdd = (full_ratings_rdd.filter(lambda r: r!= full_header)\n",
    "                   .map(lambda r: r.split(\",\"))\n",
    "                   .map(lambda r: (int(r[0]), int(r[1]), float(r[2]))).cache())\n",
    "\n",
    "print(full_ratings_rdd.take(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many records in the full dataset?  27753444\n"
     ]
    }
   ],
   "source": [
    "print(\"How many records in the full dataset? \", full_ratings_rdd.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For testing on the full dataset, the MSE is:  0.8644451910268783\n"
     ]
    }
   ],
   "source": [
    "train_rdd, test_rdd = full_ratings_rdd.randomSplit([8, 2], seed = 17)\n",
    "test_for_preds = test_rdd.map(lambda r: (int(r[0]), int(r[1])))\n",
    "\n",
    "\n",
    "full_model = ALS.train(train_rdd, best_rank, itr, seed=123, lambda_ = best_lambda)\n",
    "preds = full_model.predictAll(test_for_preds).map(lambda r: ((int(r[0]), int(r[1])), float(r[2])))\n",
    "rates_and_preds = test_rdd.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(preds)\n",
    "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "\n",
    "print(\"For testing on the full dataset, the MSE is: \", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_rdd, test_rdd, preds, rates_and_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load full movie file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'Toy Story (1995)'), (2, 'Jumanji (1995)'), (3, 'Grumpier Old Men (1995)')]\n"
     ]
    }
   ],
   "source": [
    "full_movies = os.path.join(data_path, \"ml-latest\", \"movies.csv\")\n",
    "full_movies_rdd = sc.textFile(full_movies)\n",
    "full_header = full_movies_rdd.take(1)[0]\n",
    "full_movies_rdd = (full_movies_rdd.filter(lambda r: r != full_header)\n",
    "                  .map(lambda r: r.split(\",\"))\n",
    "                  .map(lambda r: (int(r[0]), r[1])).cache())\n",
    "\n",
    "print(full_movies_rdd.take(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many movies are there in the full movie.csv file?  58098\n"
     ]
    }
   ],
   "source": [
    "print(\"How many movies are there in the full movie.csv file? \", full_movies_rdd.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the number of ratings and average ratins for each movie\n",
    "def count_rating_and_get_ave(ID_ratings):\n",
    "    count = len(ID_ratings[1])\n",
    "    return ID_ratings[0], (count, float(sum(ID_ratings[1])/count))\n",
    "\n",
    "movieID_and_ratings = full_ratings_rdd.map(lambda r: (r[1], r[2])).groupByKey().map(count_rating_and_get_ave)\n",
    "movieID_and_counts = movieID_and_ratings.map(lambda r: (r[0], r[1][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie ID, num. of ratings, ave. ratings:  [(1449, (6867, 3.918377748652978)), (828, (1736, 3.1474654377880182))]\n",
      "Movie ID, num. of ratings:  [(1449, 6867), (828, 1736)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Movie ID, num. of ratings, ave. ratings: \", movieID_and_ratings.take(2))\n",
    "print(\"Movie ID, num. of ratings: \", movieID_and_counts.take(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add new user ratings to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 260, 4.0), (0, 1, 3.0)]\n"
     ]
    }
   ],
   "source": [
    "new_user = 0\n",
    "new_user_ratings = [(new_user, 260, 4.0), (new_user,   1, 3.0), (new_user,  16, 3.0), (new_user, 25,  4.0),\n",
    "                    (new_user,  32, 4.0), (new_user, 335, 1.0), (new_user, 379, 1.0), (new_user, 296, 3.0),\n",
    "                    (new_user, 858, 5.0), (new_user,  50, 4.0)]\n",
    "new_user_ratings_rdd = sc.parallelize(new_user_ratings)\n",
    "\n",
    "## union new_user_ratings with existing ratings\n",
    "full_ratings_rdd = full_ratings_rdd.union(new_user_ratings_rdd)\n",
    "\n",
    "## print to check\n",
    "print(new_user_ratings_rdd.take(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best rank and lambda for the model: 12, 0.2\n",
      "Re-training takes 156.72719621658325 seconds\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "start = time()\n",
    "print(f\"Best rank and lambda for the model: {best_rank}, {best_lambda}\")\n",
    "new_ratings_model = ALS.train(full_ratings_rdd, best_rank, itr, seed=123, lambda_ = best_lambda)\n",
    "print(f\"Re-training takes {float(time()-start)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now we can get recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_rated = set(l[1] for l in new_user_ratings)\n",
    "new_user_unrated = full_movies_rdd.filter(lambda l: l[0] not in new_user_rated).map(lambda l: (new_user, l[0]))\n",
    "new_user_recommendations = new_ratings_model.predictAll(new_user_unrated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rating(user=0, product=116688, rating=0.9103302632655832), Rating(user=0, product=57044, rating=2.6552582665331936), Rating(user=0, product=69199, rating=2.034827451262054)]\n"
     ]
    }
   ],
   "source": [
    "print(new_user_recommendations.take(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We have our recommendations ready.\n",
    "## Now we can print out the 25 movies with the highest predicted ratings for this new user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_movieID_ratings = (new_user_recommendations.map(lambda l: (l[1], (l[0], l[2])))\n",
    "                      .join(full_movies_rdd).join(movieID_and_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(125970, (((0, 2.2831169342749904), 'Halloweentown (1998)'), 148)), (7410, (((0, 2.5355211999056335), '\"Osterman Weekend'), 177))]\n"
     ]
    }
   ],
   "source": [
    "print(new_movieID_ratings.take(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## So we need to flat this down a bit in order to have (userID, Title, Rating, Ratings Count)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 125970, 'Halloweentown (1998)', 2.2831169342749904, 148), (0, 7410, '\"Osterman Weekend', 2.5355211999056335, 177)]\n"
     ]
    }
   ],
   "source": [
    "user_movieID_title_rating_count = new_movieID_ratings.map(lambda l: (l[1][0][0][0], l[0], l[1][0][1],\n",
    "                                                                     l[1][0][0][1], l[1][1]))\n",
    "print(user_movieID_title_rating_count.take(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommended movies:\n",
      "# UserID, MovieID, MovieTitle, PredictedRating, rating count\n",
      "(0, 171495, 'Cosmos', 3.7945052255766054, 157)\n",
      "(0, 26082, 'Harakiri (Seppuku) (1962)', 3.7348204017080247, 679)\n",
      "(0, 171011, 'Planet Earth II (2016)', 3.7302233323374954, 853)\n",
      "(0, 159817, 'Planet Earth (2006)', 3.723779938958276, 1384)\n",
      "(0, 105250, '\"Century of the Self', 3.721210227899121, 213)\n",
      "(0, 101850, 'Death on the Staircase (Soupçons) (2004)', 3.6879269831915624, 130)\n",
      "(0, 6669, 'Ikiru (1952)', 3.6780773173121633, 1551)\n",
      "(0, 26587, '\"Decalogue', 3.6570485630191625, 547)\n",
      "(0, 172591, 'The Godfather Trilogy: 1972-1990 (1992)', 3.6528542110405535, 421)\n",
      "(0, 170705, 'Band of Brothers (2001)', 3.650982132699011, 984)\n",
      "(0, 7926, 'High and Low (Tengoku to jigoku) (1963)', 3.648158267529952, 812)\n",
      "(0, 6818, 'Come and See (Idi i smotri) (1985)', 3.6403026168460118, 703)\n",
      "(0, 2019, 'Seven Samurai (Shichinin no samurai) (1954)', 3.633078233250661, 14578)\n",
      "(0, 1178, 'Paths of Glory (1957)', 3.625288643496362, 4508)\n",
      "(0, 3030, 'Yojimbo (1961)', 3.624705240347988, 4328)\n",
      "(0, 163809, 'Over the Garden Wall (2013)', 3.6210524632236236, 377)\n",
      "(0, 8684, '\"Man Escaped', 3.6203297529858878, 440)\n",
      "(0, 6918, '\"Unvanquished', 3.6200939312674993, 398)\n",
      "(0, 8484, '\"Human Condition I', 3.6195038612338806, 151)\n",
      "(0, 1212, '\"Third Man', 3.619244862836824, 7980)\n"
     ]
    }
   ],
   "source": [
    "top_movies = user_movieID_title_rating_count.filter(lambda l: l[4]>100).takeOrdered(20, key=lambda l: -l[3])\n",
    "print(\"Top recommended movies:\\n# UserID, MovieID, MovieTitle, PredictedRating, rating count\")\n",
    "print(\"\\n\".join(map(str, top_movies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## another usefull usecase is to get the predicted rating for for a specific movie for a given user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 500, 2.458496060948492)]\n"
     ]
    }
   ],
   "source": [
    "new_data = sc.parallelize([(0, 500)])\n",
    "individual_rating_rdd = new_ratings_model.predictAll(new_data).map(lambda r: (r[0], r[1], r[2]))\n",
    "print(individual_rating_rdd.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### persisting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import MatrixFactorizationModel\n",
    "model_path = os.path.join(\"./\", \"models\", \"./movie_lens_ALS_model\")\n",
    "full_model.save(sc, model_path)\n",
    "loaded_model = MatrixFactorizationModel.load(sc, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "del full_ratings_rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part 2: building a web service with spark and Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### building the recommendataion engine (engine.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.mllib.recommendation import ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommendationEngine(object):\n",
    "    \"\"\"Movie recommendation engine\"\"\"\n",
    "    \n",
    "    def __init__(self, sc, data_path):\n",
    "        \"\"\"Initialize the engine given SparkContext and path to the data\"\"\"\n",
    "        logger.info(\"Setting up the Movie Recommendation Engine ... (I call it 'Mre')\")\n",
    "        self.sc = sc\n",
    "        \"\"\"Load rating data\"\"\"\n",
    "        logger.info(\"Loading rating data ... (make sure it is called 'raings.csv')\")\n",
    "        file_path = os.path.join(data_path, \"ratings.csv\")\n",
    "        data_raw = self.sc.textFile(file_path)\n",
    "        header = data_raw.take(1)[0]\n",
    "        self.ratings_rdd = (data_raw.filter(lambda l: l != header).map(lambda l: l.split(\",\"))\n",
    "                                    .map(lambda l: (int(l[0]), int(l[1]), float(l[2]))).cache())\n",
    "        \n",
    "        \"\"\"Load movie data\"\"\"\n",
    "        logger.info(\"Loading movie data ... (make sure it is called 'movies.csv')\")\n",
    "        file_path = os.path.join(data_path, \"movies.csv\")\n",
    "        data_raw = self.sc.textFile(file_path)\n",
    "        header = data_raw.take(1)[0]\n",
    "        self.movie_title_genre_rdd = (data_raw.filter(lambda l: l != header).map(lambda l: l.split(\",\"))\n",
    "                                               .map(lambda l: (int(l[0]), l[1], l[2])).cache())\n",
    "        self.movie_title_rdd = self.movie_title_genre_rdd.map(lambda l: (l[0], l[1])).cache()\n",
    "        \n",
    "        \"\"\"Compute movie ave ratings and rating counts\"\"\"\n",
    "        self.__count_ave_ratings()\n",
    "        \n",
    "        \"\"\"Train the model\"\"\"\n",
    "        self.rank = 8\n",
    "        self.seed = 16807\n",
    "        self.iters = 10\n",
    "        self.reg_param = 0.1\n",
    "        self.__train_model()\n",
    "    \n",
    "    def __count_ave_ratings(self):\n",
    "        \"\"\"update movie average ratins and rating counts using self.ratings_rdd\"\"\"\n",
    "        logger.info(\"For every movieID, computing average ratings and number of ratings ...\")\n",
    "        movieID_ratings = self.ratings_rdd.map(lambda l: (l[1], l[2])).groupByKey()\n",
    "        self.movie_ratings_count_rdd = movieID_ratings.map(count_rating_and_get_ave)\n",
    "    \n",
    "    def __train_model(self):\n",
    "        \"\"\"train the ALS model with rdd\"\"\"\n",
    "        logger.info(\"Training the model ...\")\n",
    "        self.model = ALS.train(self.ratings_rdd, self.rank, self.iters, seed=self.seed, lambda_ = self.reg_param)\n",
    "        logger.info(\"ALS model is built !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ratings(self, new_ratings):\n",
    "    \"\"\"We should be able to add new ratings to the dataset\"\"\"\n",
    "    new_ratings_rdd = self.sc.parallelize(new_ratings)\n",
    "    ## add the new ratings to the existing ratings_rdd\n",
    "    self.ratings_rdd = self.ratings_rdd.union(new_ratings_rdd)\n",
    "    ## re-compute movie rating count and average ratings\n",
    "    self.__count_ave_ratings()\n",
    "    ## re-train the model with the new ratings_rdd\n",
    "    self.__train_model()\n",
    "    return\n",
    "\n",
    "RecommendationEngine.add_ratings = add_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## making recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __predict_ratings(self, user_and_movie):\n",
    "    \"\"\" Predict ratings for given rdd with format (userID, movieID)\n",
    "    Returns: rdd with format (userID, movieID, movieTitle, rating, rating_count)\n",
    "    \"\"\"\n",
    "    predicted_rdd = self.model.predictAll(user_and_movie).map(lambda l: (l[0], l[1], l[2]))\n",
    "    movie_user_rating_rdd = (predicted_rdd.map(lambda l: (l[1], (l[0], l[2]))).join(self.movie_title_rdd)\n",
    "                         .join(self.movie_ratings_count_rdd))\n",
    "    movie_user_rating_rdd = movie_user_rating_rdd.map(lambda l: (l[1][0][0][0], l[0], l[1][0][1], l[1][1]))\n",
    "    return movie_user_rating_rdd\n",
    "\n",
    "def get_top_ratings(self, user_id, movie_num, num_rating_thresh=25):\n",
    "    \"\"\"get movie_num top rating movies for this user\n",
    "    on the condition that among the returned result each movie has more than num_rating_thresh ratings\n",
    "    \"\"\"\n",
    "    user_unrated_rdd = (self.ratings_rdd.filter(lambda l: l[0] != user_id)\n",
    "                            .map(lambda l: (user_id, l[1])))\n",
    "    ratings = (self.__predict_ratings(user_unrated_rdd).filter(lambda l: l[4] > num_rating_thresh)\n",
    "                   .takeOrdered(movie_num, key=lambda l: -l[3]))\n",
    "    return ratings\n",
    "    \n",
    "RecommendationEngine.__predict_ratings = __predict_ratings\n",
    "RecommendationEngine.get_user_rated_set = get_user_rated_set\n",
    "RecommendationEngine.get_top_ratings = get_top_ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We will also want to get ratings to particular movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratings_for_movies(self, user_id, movie_ids):\n",
    "    requested_rdd = self.sc.parallelize(movie_ids).map(lambda l: (user_id, l))\n",
    "    ratings = self.__predict_ratings(requested_rdd)\n",
    "    return ratings\n",
    "\n",
    "RecommendationEngine.get_ratings_for_movies = get_ratings_for_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building a Web API around our Engine using Flask (app.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Blueprint\n",
    "main = Blueprint('main', __name__)\n",
    "\n",
    "import json\n",
    "from engine import RecommendationEngine\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request\n",
    "\n",
    "@main.route(\"/<int:user_id>/ratings/top/<int:count>\", methods=[\"GET\"])\n",
    "def top_ratings(user_id, count):\n",
    "    logger.debug(f\"User {user_id}'s TOP {count} movies requested ... \")\n",
    "    top_ratings = recommendation_engine.get_top_ratings(user_id, count)\n",
    "    return json.dumps(top_ratings)\n",
    "\n",
    "@main.route(\"/<int:user_id>/ratings/<int:movie_id>\", method=[\"GET\"])\n",
    "def movie_ratings(user_id, movie_id):\n",
    "    logger.debug(f\"User {user_id} rating for movie {movie_id} requested ... \")\n",
    "    user_movie_rating = recommendation_engine.get_ratings_for_movies(user_id, [movie_id])\n",
    "    return json.dumps(user_movie_rating)\n",
    "\n",
    "@main.route(\"/<int:user_id>/ratings/\", method=[\"POST\"])\n",
    "def add_ratings(user_id):\n",
    "    ## get ratings from the Flask POST request object\n",
    "    ratings_list = request.form.keys()[0].strip().split(\"\\n\")\n",
    "    ratings_list = map(lambda x: x.split(\",\"), ratings_list)\n",
    "    ## create a list with the format required by the engine: user_id, movie_id, ratings\n",
    "    new_ratings = map(lambda x: (user_id, int(x[0]), float(x[1])), ratings_list)\n",
    "    ## add ratings to the engine\n",
    "    recommendation_engine.add_ratings(new_ratings)\n",
    "    return json.dumps(new_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creat app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_app(spark_context, data_path):\n",
    "    global recommendation_engine\n",
    "    recommendation_engine = RecommendationEngine(sc, data_path)\n",
    "    app = Flask(__name__)\n",
    "    app.register_blueprint(main)\n",
    "    return app\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_movieID_ratings = [(260,9), (1,8), (16,7), (25,8), (32,9), (335,4), (379,3), (296,7), (858,10), (50,8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deploying a WSGI Server using CherryPy (server.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting CherryPy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/2c/73e16c77b20c01c277c42a1b4ee29ebadae2b18104570b920cadc3e51413/CherryPy-18.5.0-py2.py3-none-any.whl (418kB)\n",
      "\u001b[K     |████████████████████████████████| 419kB 5.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting zc.lockfile\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/2a/268389776288f0f26c7272c70c36c96dcc0bdb88ab6216ea18e19df1fadd/zc.lockfile-2.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: more-itertools in /anaconda3/envs/py36/lib/python3.6/site-packages (from CherryPy) (8.0.2)\n",
      "Collecting cheroot>=8.2.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/be/51b1517c6dbf3851d44b36ff08a6e1012464149f89f74c46b29d2f76545e/cheroot-8.2.1-py2.py3-none-any.whl (79kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 10.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jaraco.collections\n",
      "  Downloading https://files.pythonhosted.org/packages/fe/06/a89652069f0a13a33701714c0c8e0cc8656bf6d21b7c6b85fde86cf06ff6/jaraco.collections-3.0.0-py2.py3-none-any.whl\n",
      "Collecting portend>=2.1.1\n",
      "  Downloading https://files.pythonhosted.org/packages/d7/79/eee70a512bffe5ceb5008f8e3326581948f50ca393c3bcb4d557e4818bd1/portend-2.6-py2.py3-none-any.whl\n",
      "Requirement already satisfied: setuptools in /anaconda3/envs/py36/lib/python3.6/site-packages (from zc.lockfile->CherryPy) (42.0.2.post20191203)\n",
      "Requirement already satisfied: six>=1.11.0 in /anaconda3/envs/py36/lib/python3.6/site-packages (from cheroot>=8.2.1->CherryPy) (1.13.0)\n",
      "Collecting jaraco.functools\n",
      "  Downloading https://files.pythonhosted.org/packages/ba/7a/ae51d7605dc471d29345c4ef1e5c0894f392b14beaf813cd7b43ec1ee1b6/jaraco.functools-3.0.0-py2.py3-none-any.whl\n",
      "Collecting jaraco.classes\n",
      "  Downloading https://files.pythonhosted.org/packages/68/ce/8f43aa0d0f18120e687ae0192fe3168630040841a3e87bed93c5fe024dbe/jaraco.classes-3.1.0-py2.py3-none-any.whl\n",
      "Collecting jaraco.text\n",
      "  Downloading https://files.pythonhosted.org/packages/50/cd/6eda44738065e844bed8fae60a229b6c46f42d0ba8d48205e9fb57e254cd/jaraco.text-3.2.0-py2.py3-none-any.whl\n",
      "Collecting tempora>=1.8\n",
      "  Downloading https://files.pythonhosted.org/packages/6e/19/dc9bb53e7fd2f72d50068089496cc65845af6669bdc4394b8557bf2d1923/tempora-2.0.0-py2.py3-none-any.whl\n",
      "Collecting importlib-resources; python_version < \"3.7\"\n",
      "  Downloading https://files.pythonhosted.org/packages/2f/f7/b4aa02cdd3ee7ebba375969d77c00826aa15c5db84247d23c89522dccbfa/importlib_resources-1.0.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pytz in /anaconda3/envs/py36/lib/python3.6/site-packages (from tempora>=1.8->portend>=2.1.1->CherryPy) (2019.3)\n",
      "Installing collected packages: zc.lockfile, jaraco.functools, cheroot, jaraco.classes, importlib-resources, jaraco.text, jaraco.collections, tempora, portend, CherryPy\n",
      "Successfully installed CherryPy-18.5.0 cheroot-8.2.1 importlib-resources-1.0.2 jaraco.classes-3.1.0 jaraco.collections-3.0.0 jaraco.functools-3.0.0 jaraco.text-3.2.0 portend-2.6 tempora-2.0.0 zc.lockfile-2.0\n"
     ]
    }
   ],
   "source": [
    "#import sys\n",
    "!{sys.executable} -m pip install CherryPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, sys, cherrypy, os\n",
    "from paste.translogger import TransLogger\n",
    "from app import create_app\n",
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_spark_context():\n",
    "    conf = SparkConf().setAppName(\"MovieLens-Recommendation-Server\")\n",
    "    sc = SparkContext(conf = conf, pyFiles = [\"engine.py\", \"app.py\"])\n",
    "    return sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_server(app):\n",
    "    ## enable WSGI access logging via Paste\n",
    "    app_logged = TransLogger(app)\n",
    "    \n",
    "    ## Mount the WSGI callable object (app) on the root directory\n",
    "    cherrypy.tree.graft(app_logged, \"/\")\n",
    "    \n",
    "    ## set the configuration for the web server\n",
    "    cherrypy.config.update( { \"engine.autoreload.com\": True,\n",
    "                              \"log.screen\": True,\n",
    "                              \"server.socket_port\": 7788,\n",
    "                              \"server.socket_host\": \"0.0.0.0\" } )\n",
    "    ## start the CherryPy WSGI web server\n",
    "    cherrypy.engine.start()\n",
    "    cherrypy.engine.block()\n",
    "\n",
    "if __name__ == \"main\":\n",
    "    ## initialize spark context\n",
    "    sc = init_spark_context()\n",
    "    data_path = path.join(\"data\", \"ml-latest\")\n",
    "    app = create_app(sc, data_path)\n",
    "    \n",
    "    ## start the web server\n",
    "    run_server(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
